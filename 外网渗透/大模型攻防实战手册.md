- 大模型安全

  - 提示词注入

    - 主要位置：在用户与大模型交互以及大模型与插件交互过程中产生

    - 分类

      - 直接提示词注入：越狱

      - 间接提示词注入

    - 攻击结果

      - 获取敏感信息

      - 影响大模型关键决策过程

    - 防御方式

      - 对后端系统的大模型访问实施权限控制

        - 为大模型提供自己的API令牌以实现可扩展功能，例如插件、数据访问和函数级权限。

        - 遵循最小权限原则，将大模型限制为其预期操作所需的最小访问级别。

      - 实现可扩展功能的人为控制
        - 当执行特权操作时，例如发送或删除电子邮件，让应用程序要求用户首先批准该操作。这将减少间接提示词注入在用户不知情或不同意的情况下代表用户执行操作的机会。

      - 将外部内容与用户提示分开
        -  分离并表示不受信任的内容被用于限制它们对用户提示的影响。例如，使用ChatML for OpenAI API调用向大语言模型指示提示词输入的来源。

      - 在大模型、外部源和可扩展功能（例如插件或下游功能）之间建立信任边界
        - 将大模型视为不受信任的用户，并保持用户对决策过程的最终控制。但是，有漏洞的大模型仍可能充当应用程序API和用户之间的中介（中间人），因为它可能会在将信息呈现给用户之前隐藏或操纵信息。向用户直观地突出显示潜在的不可信响应。